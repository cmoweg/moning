{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Moning Lab-03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNaLOPh7wCiufICOYijGthJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmoweg/moning/blob/master/Lab%2008-2%20Multi%20Layer%20Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7zcUawBggWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e6a72bc0-7343-47db-9783-c8df3b76a865"
      },
      "source": [
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(777)\n",
        "\n",
        "\n",
        "learning_rate = 0.5\n",
        "\n",
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\n",
        "# nn layers\n",
        "w1 = torch.Tensor(2, 2).to(device)\n",
        "b1 = torch.Tensor(2).to(device)\n",
        "w2 = torch.Tensor(2, 1).to(device)\n",
        "b2 = torch.Tensor(1).to(device)\n",
        "def sigmoid(x):\n",
        "  # sigmoid function\n",
        "  return 1.0 / (1.0 + torch.exp(-x))\n",
        "  # return torch.div(torch.tensor(1), torch.add(torch.tensor(1.0), torch.exp(-x)))\n",
        "def sigmoid_prime(x):\n",
        " # derivative of the sigmoid function\n",
        "  return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "for step in range(10001):\n",
        "\n",
        "  # forward\n",
        "  l1 = torch.add(torch.matmul(X, w1), b1)\n",
        "  a1 = sigmoid(l1)\n",
        "  l2 = torch.add(torch.matmul(a1, w2), b2)\n",
        "  Y_pred = sigmoid(l2)\n",
        "  # cross entropy\n",
        "  cost = -torch.mean(Y * torch.log(Y_pred) + (1 - Y) * torch.log(1 - Y_pred))\n",
        "\n",
        "  # Back prop (chain rule)\n",
        "\n",
        "  # Loss derivative\n",
        "  # https://math.stackexchange.com/a/2503773 답변 참고\n",
        "  d_Y_pred = (Y_pred - Y) / (Y_pred * (1.0 - Y_pred) + 1e-7)\n",
        "\n",
        "  # Layer 2\n",
        "  d_l2 = d_Y_pred * sigmoid_prime(l2)\n",
        "  d_b2 = d_l2\n",
        "  d_w2 = torch.matmul(torch.transpose(a1, 0, 1), d_b2)\n",
        "\n",
        "  # Layer 1\n",
        "  d_a1 = torch.matmul(d_b2, torch.transpose(w2, 0, 1))\n",
        "  d_l1 = d_a1 * sigmoid_prime(l1)\n",
        "  d_b1 = d_l1\n",
        "  d_w1 = torch.matmul(torch.transpose(X, 0, 1), d_b1)\n",
        "\n",
        "  # Back prop (chain rule)\n",
        "  # Weight update\n",
        "  # bias같은 경우는 mean 함수로 인해 1/2가 되는 것인가?\n",
        "  w1 = w1 - learning_rate * d_w1\n",
        "  b1 = b1 - learning_rate * torch.mean(d_b1, 0)\n",
        "  w2 = w2 - learning_rate * d_w2\n",
        "  b2 = b2 - learning_rate * torch.mean(d_b2, 0)\n",
        "  if step % 100 == 0:\n",
        "    print(step, cost.item())\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.6931471824645996\n",
            "100 0.6931471824645996\n",
            "200 0.6931471824645996\n",
            "300 0.6931471824645996\n",
            "400 0.6931471824645996\n",
            "500 0.6931471824645996\n",
            "600 0.6931471824645996\n",
            "700 0.6931471824645996\n",
            "800 0.6931471824645996\n",
            "900 0.6931471824645996\n",
            "1000 0.6931471824645996\n",
            "1100 0.6931471824645996\n",
            "1200 0.6931470632553101\n",
            "1300 0.693146824836731\n",
            "1400 0.6931449174880981\n",
            "1500 0.6931333541870117\n",
            "1600 0.6930424571037292\n",
            "1700 0.6915000677108765\n",
            "1800 0.6193432807922363\n",
            "1900 0.36937594413757324\n",
            "2000 0.11909997463226318\n",
            "2100 0.05162293463945389\n",
            "2200 0.03089142218232155\n",
            "2300 0.02161503955721855\n",
            "2400 0.016487734392285347\n",
            "2500 0.013270776718854904\n",
            "2600 0.011077230796217918\n",
            "2700 0.009491345845162868\n",
            "2800 0.0082940012216568\n",
            "2900 0.007359487470239401\n",
            "3000 0.006610589101910591\n",
            "3100 0.005997548811137676\n",
            "3200 0.005486822221428156\n",
            "3300 0.005054939072579145\n",
            "3400 0.004685106221586466\n",
            "3500 0.004364978522062302\n",
            "3600 0.004085187800228596\n",
            "3700 0.0038386445958167315\n",
            "3800 0.003619813360273838\n",
            "3900 0.0034242593683302402\n",
            "4000 0.0032485113479197025\n",
            "4100 0.0030897301621735096\n",
            "4200 0.0029455884359776974\n",
            "4300 0.0028140756767243147\n",
            "4400 0.0026937653310596943\n",
            "4500 0.0025831731036305428\n",
            "4600 0.002481204690411687\n",
            "4700 0.0023869145661592484\n",
            "4800 0.0022994489409029484\n",
            "4900 0.0022181335370987654\n",
            "5000 0.0021423236466944218\n",
            "5100 0.0020714355632662773\n",
            "5200 0.0020050648599863052\n",
            "5300 0.0019427469233050942\n",
            "5400 0.0018842123681679368\n",
            "5500 0.001829042099416256\n",
            "5600 0.0017769519472494721\n",
            "5700 0.0017277916194871068\n",
            "5800 0.0016812175745144486\n",
            "5900 0.0016370202647522092\n",
            "6000 0.0015951095847412944\n",
            "6100 0.0015552910044789314\n",
            "6200 0.0015173853607848287\n",
            "6300 0.0014813027810305357\n",
            "6400 0.0014468488516286016\n",
            "6500 0.0014139636186882854\n",
            "6600 0.0013825276400893927\n",
            "6700 0.0013523913221433759\n",
            "6800 0.0013235844671726227\n",
            "6900 0.0012960026506334543\n",
            "7000 0.0012694961624220014\n",
            "7100 0.001244035200215876\n",
            "7200 0.0012195899616926908\n",
            "7300 0.0011960705742239952\n",
            "7400 0.0011734472354874015\n",
            "7500 0.001151630305685103\n",
            "7600 0.001130649703554809\n",
            "7700 0.0011103559518232942\n",
            "7800 0.0010908087715506554\n",
            "7900 0.0010719334241002798\n",
            "8000 0.0010537002235651016\n",
            "8100 0.0010360493324697018\n",
            "8200 0.00101902533788234\n",
            "8300 0.0010024942457675934\n",
            "8400 0.0009865002939477563\n",
            "8500 0.0009710140875540674\n",
            "8600 0.0009560502949170768\n",
            "8700 0.0009414448286406696\n",
            "8800 0.0009273319155909121\n",
            "8900 0.0009136220905929804\n",
            "9000 0.0009003450395539403\n",
            "9100 0.0008874114137142897\n",
            "9200 0.0008748209802433848\n",
            "9300 0.0008626037742942572\n",
            "9400 0.0008506999583914876\n",
            "9500 0.0008391542360186577\n",
            "9600 0.0008279220201075077\n",
            "9700 0.0008169583743438125\n",
            "9800 0.0008062932756729424\n",
            "9900 0.0007958670030348003\n",
            "10000 0.0007857241434976459\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}